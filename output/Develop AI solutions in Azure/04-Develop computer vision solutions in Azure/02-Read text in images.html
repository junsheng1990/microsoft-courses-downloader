<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Read text in images</title>
    <style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    h1 { color: #0078d4; border-bottom: 2px solid #0078d4; padding-bottom: 10px; }
    h2 { color: #333; margin-top: 40px; border-bottom: 1px solid #ddd; padding-bottom: 8px; }
    .section { margin-bottom: 40px; }
    .section-header { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    .section-header a { color: #0078d4; text-decoration: none; }
    .section-header a:hover { text-decoration: underline; }
    img { max-width: 100%; height: auto; }
    pre { background: #f4f4f4; padding: 15px; overflow-x: auto; border-radius: 5px; }
    code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background: #f5f5f5; }
    .NOTE, .TIP { padding: 12px 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid; }
    .NOTE { background-color: #e7f3ff; border-color: #0078d4; }
    .NOTE > p:first-child { font-weight: bold; color: #0078d4; margin-top: 0; }
    .TIP { background-color: #e8f5e9; border-color: #4caf50; }
    .TIP > p:first-child { font-weight: bold; color: #2e7d32; margin-top: 0; }
</style>
</head>
<body>
    <h1>Read text in images</h1>

    <div class="section">
        <div class="section-header">
            <h2>1. Introduction</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/1-introduction">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/1-introduction</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.introduction">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">2 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>We live in a digital world, in which data is increasingly captured as images. Often, those images contain text, which you need to be able to extract from their pixelated format in the image for processing, indexing, and other tasks. Everyday examples include:</p>
<ul>
<li>Meeting a new business associate and taking a photograph of their business card to store their contact details digitally.</li>
<li>Scanning a document or ID card to include in an application for a government or commercial service.</li>
<li>Taking a photo of a menu or recipe to store it in a digital notebook.</li>
<li>Photographing street signs or store fronts so you can submit the text they contain to a translation app.</li>
<li>Digitizing handwritten notes using a cellphone camera.</li>
</ul>
<p><img alt="Diagram of an image containing text being read by the Azure Vision image analysis service." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/read-text-images-documents-with-computer-vision-service/media/optical-character-recognition.png"/></p>
<p>In this module, we'll explore the <em>optical character recognition</em> (OCR) capabilities of the Azure Vision <em>Image Analysis</em> API, which makes these scenarios, and more, possible.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>2. Explore Azure AI options for reading text</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/2-options-read-text">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/2-options-read-text</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Explore Azure AI options for reading text</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.options-for-reading-text">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>There are multiple Azure services that read text from documents and images, each optimized for results depending on the input and the specific requirements of your application.</p>
<h2 id="azure-vision">Azure Vision</h2>
<p><img alt="Azure Vision icon" data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/read-text-images-documents-with-computer-vision-service/media/ai-vision.png"/></p>
<p>Azure Vision includes an <em>image analysis</em> capability that supports <em>optical character recognition</em> (OCR). Consider using Azure Vision in the following scenarios:</p>
<ul>
<li><strong>Text location and extraction from scanned documents</strong>: Azure Vision is a great solution for general, unstructured documents that have been scanned as images. For example, reading text in labels, menus, or business cards.</li>
<li><strong>Finding and reading text in photographs</strong>: Examples include photo's that include street signs and store names.</li>
<li><strong>Digital asset management (DAM)</strong>: Azure Vision includes functionality for analyzing images beyond extracting text; including object detection, describing or categorizing an image, generating smart-cropped thumbnails and more. These capabilities make it a useful service when you need to catalog, index, or analyze large volumes of digital image-based content.</li>
</ul>
<h2 id="azure-document-intelligence">Azure Document Intelligence</h2>
<p><img alt="Azure Document Intelligence icon" data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/read-text-images-documents-with-computer-vision-service/media/document-intelligence.png"/></p>
<p>Azure Document Intelligence is a service that you can use to extract information from complex digital documents. Azure Document Intelligence is designed for extracting text, key-value pairs, tables, and structures from documents automatically and accurately. Key considerations for choosing Azure Document Intelligence include:</p>
<ul>
<li><strong>Form processing</strong>: Azure Document Intelligence is specifically designed to extract data from forms, invoices, receipts, and other structured documents.</li>
<li><strong>Prebuilt models</strong>: Azure Document Intelligence provides prebuilt models for common document types to reduce complexity and integrate into workflows or applications.</li>
<li><strong>Custom models</strong>: Creating custom models tailored to your specific documents, makes Azure Document Intelligence a flexible solution that can be used in many business scenarios.</li>
</ul>
<h2 id="azure-content-understanding">Azure Content Understanding</h2>
<p><img alt="Azure Content Understanding icon" data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/read-text-images-documents-with-computer-vision-service/media/content-understanding.png"/></p>
<p>Azure Content Understanding is a service that you can use to analyze and extract information from multiple kinds of content; including documents, images, audio streams, and video. It is suitable for:</p>
<ul>
<li><strong>Multimodal content extraction</strong>: Extracting content and structured fields from documents, forms, audio, video, and images.</li>
<li><strong>Custom content analysis scenarios</strong>: Support for customizable analyzers enables you to extract specific content or fields tailored to business needs.</li>
</ul>
<div class="NOTE">
<p>Note</p>
<p>In the rest of this module, we'll focus on the OCR image analysis feature in <strong>Azure Vision</strong>. To learn more about Azure Document Intelligence and Azure AI Content understanding, consider completing the following training modules:</p>
<ul>
<li><a data-linktype="absolute-path" href="/en-us/training/modules/plan-form-recognizer-solution/">Plan an Azure Document Intelligence solution</a></li>
<li><a data-linktype="absolute-path" href="/en-us/training/modules/analyze-content-ai/">Analyze content with Azure Content Understanding</a></li>
</ul>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>3. Read text with Azure Vision Image Analysis</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/4-use-read-api">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/4-use-read-api</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Read text with Azure Vision Image Analysis</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.using-read-api">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">6 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>To use Azure Vision for image analysis, including optical character recognition, you must provision an Azure Vision resource in an Azure subscription. The resource can be:</p>
<ul>
<li>A <strong>Foundry Tools</strong> resource (either deployed as part of a Microsoft Foundry hub and project, or as a standalone resource).</li>
<li>An <strong>Azure Vision</strong> resource.</li>
</ul>
<p>To use your deployed resource in an application, you must connect to its <em>endpoint</em> using either key-based authentication or Microsoft Entra ID authentication. You can find the endpoint for your resource in the Azure portal, or if you're working in a Microsoft Foundry project, in the Microsoft Foundry portal. The endpoint is in the form of a URL, and typically looks something like this:</p>
<pre><code>https://&lt;resource_name&gt;.cognitiveservices.azure.com/
</code></pre>
<p>After establishing a connection, you can use the OCR feature by calling the <strong>ImageAnalysis</strong> function (via the REST API or with an equivalent SDK method), passing the image URL or binary data, and optionally specifying the language the text is written in (with a default value of <strong>en</strong> for English).</p>
<pre><code class="lang-rest">https://&lt;endpoint&gt;/computervision/imageanalysis:analyze?features=read&amp;...
</code></pre>
<div class="zone has-pivot" data-pivot="python">
<p>To use the Azure Vision Python SDK to extract text from an image, install the <strong>azure-ai-vision-imageanalysis</strong> package. Then, in your code, use either key-based authentication or Microsoft Entra ID authentication to connect an <strong>ImageAnalysisClient</strong> object to an Azure Vision resource. To find and read text in an image, call the <strong>analyze</strong> (or <strong>analyze_from_url</strong>) method, specifying the <strong>VisualFeatures.READ</strong> enumeration.</p>
<pre><code class="lang-python">from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from azure.core.credentials import AzureKeyCredential

client = ImageAnalysisClient(
    endpoint="&lt;YOUR_RESOURCE_ENDPOINT&gt;",
    credential=AzureKeyCredential("&lt;YOUR_AUTHORIZATION_KEY&gt;")
)

result = client.analyze(
    image_data=&lt;IMAGE_DATA_BYTES&gt;, # Binary data from your image file
    visual_features=[VisualFeatures.READ],
    language="en",
)
</code></pre>
</div>
<div class="zone has-pivot" data-pivot="csharp">
<p>To use the Azure Vision .NET SDK to extract text from an image, install the <strong>Azure.AI.Vision.ImageAnalysis</strong> package. Then, in your code, use either key-based authentication or Microsoft Entra ID authentication to connect an <strong>ImageAnalysisClient</strong> object to an Azure Vision resource. To find and read text in an image, call the <strong>Analyze</strong> method, specifying the <strong>VisualFeatures.Read</strong> enumeration.</p>
<pre><code class="lang-csharp">using Azure.AI.Vision.ImageAnalysis;

ImageAnalysisClient client = new ImageAnalysisClient(
    "&lt;YOUR_RESOURCE_ENDPOINT&gt;",
    new AzureKeyCredential("&lt;YOUR_AUTHORIZATION_KEY&gt;"));

ImageAnalysisResult result = client.Analyze(
    &lt;IMAGE_DATA_BYTES&gt;, // Binary data from your image file
    VisualFeatures.Read,
    new ImageAnalysisOptions { Language = t"en" });
</code></pre>
</div>
<p>The results of the Read OCR function are returned synchronously, either as JSON or the language-specific object of a similar structure. These results are broken down in <em>blocks</em> (with the current service only using one block), then <em>lines</em>, and then <em>words</em>. Additionally, the text values are included at both the <em>line</em> and <em>word</em> levels, making it easier to read entire lines of text if you don't need to extract text at the individual <em>word</em> level.</p>
<pre><code class="lang-JSON">{
    "metadata":
    {
        "width": 500,
        "height": 430
    },
    "readResult":
    {
        "blocks":
        [
            {
                "lines":
                [
                    {
                        "text": "Hello World!",
                        "boundingPolygon":
                        [
                            {"x":251,"y":265},
                            {"x":673,"y":260},
                            {"x":674,"y":308},
                            {"x":252,"y":318}
                        ],
                        "words":
                        [
                            {
                                "text":"Hello",
                                "boundingPolygon":
                                [
                                    {"x":252,"y":267},
                                    {"x":307,"y":265},
                                    {"x":307,"y":318},
                                    {"x":253,"y":318}
                                ],
                            "confidence":0.996
                            },
                            {
                                "text":"World!",
                                "boundingPolygon":
                                [
                                    {"x":318,"y":264},
                                    {"x":386,"y":263},
                                    {"x":387,"y":316},
                                    {"x":319,"y":318}
                                ],
                                "confidence":0.99
                            }
                        ]
                    },
                ]
            }
        ]
    }
}
</code></pre>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>4. Exercise - Read text in images</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/5-exercise">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/5-exercise</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Read text in images</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.exercise">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">30 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Now it's your turn to try using the OCR capabilities of Azure Vision.</p>
<p>In this exercise, you use the Azure Vision Image Analysis SDK to develop a client application that extracts text from images.</p>
<div class="NOTE">
<p>Note</p>
<p>To complete this lab, you need an <strong><a data-linktype="external" href="https://azure.microsoft.com/pricing/purchase-options/azure-account?cid=msft_learn">Azure subscription</a></strong> in which you have administrative access.</p>
</div>
<p>Launch the exercise and follow the instructions.</p>
<p><a data-linktype="external" href="https://go.microsoft.com/fwlink/?linkid=2320100&amp;azure-portal=true"><img alt="Button to launch exercise." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/read-text-images-documents-with-computer-vision-service/media/launch-exercise.png"/></a></p>
<div class="TIP">
<p>Tip</p>
<p>After completing the exercise, if you've finished exploring Foundry Tools, delete the Azure resources that you created during the exercise.</p>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>5. Module assessment</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/6-knowledge-check">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/6-knowledge-check</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Module assessment</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.knowledge-check">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div aria-hidden="true" hidden="" id="module-unit-content">
</div>
<form aria-hidden="true" aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" hidden="" id="question-container" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Which service should you use to locate and read text in signs within a photograph of a street?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Azure Language Named Entity Recognition</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Azure Document Intelligence</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Azure Vision Image Analysis</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which visual feature enumeration should you use to return OCR results from an image analysis call?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>VisualFeatures.Caption</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>VisualFeatures.Read</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>VisualFeatures.Tags</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Text location information in an image is returned at which levels by Azure Vision Image Analysis?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>The location of individual <em>words</em> only.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>A single <em>block</em> containing all of the text in the image.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>A <em>block</em> containing the location of <em>lines</em> of text as well as individual <em>words</em>.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<form aria-hidden="true" aria-label="Knowledge check" class="margin-top-xs" data-bi-name="module-assessment" hidden="" id="module-assessment-questions-form" role="form">
<fieldset class="field">
<div id="module-assessment-questions-container" role="list"></div>
<div aria-hidden="true" hidden="" id="module-assessment-objectives-container" role="list"></div>
<div id="module-assessment-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-module-assessment-question-error" role="alert">You must answer all questions before checking your work.</p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>6. Summary</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/7-summary">https://learn.microsoft.com/en-us/training/modules/read-text-images-documents-with-computer-vision-service/7-summary</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.read-text-images-documents-with-computer-vision-service.summary">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">1 minute</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this module, you learned how to provision an Azure Vision resource and use it from a client application to extract text from images.</p>
<p>To learn more about using Azure Vision for OCR, see the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/computer-vision/overview-ocr">OCR - Optical Character Recognition</a> in the Azure Vision documentation.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>
</body>
</html>