<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Create speech-enabled apps with Microsoft Foundry</title>
    <style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    h1 { color: #0078d4; border-bottom: 2px solid #0078d4; padding-bottom: 10px; }
    h2 { color: #333; margin-top: 40px; border-bottom: 1px solid #ddd; padding-bottom: 8px; }
    .section { margin-bottom: 40px; }
    .section-header { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    .section-header a { color: #0078d4; text-decoration: none; }
    .section-header a:hover { text-decoration: underline; }
    img { max-width: 100%; height: auto; }
    pre { background: #f4f4f4; padding: 15px; overflow-x: auto; border-radius: 5px; }
    code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background: #f5f5f5; }
    .NOTE, .TIP { padding: 12px 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid; }
    .NOTE { background-color: #e7f3ff; border-color: #0078d4; }
    .NOTE > p:first-child { font-weight: bold; color: #0078d4; margin-top: 0; }
    .TIP { background-color: #e8f5e9; border-color: #4caf50; }
    .TIP > p:first-child { font-weight: bold; color: #2e7d32; margin-top: 0; }
</style>
</head>
<body>
    <h1>Create speech-enabled apps with Microsoft Foundry</h1>

    <div class="section">
        <div class="section-header">
            <h2>1. Introduction</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/1-introduction">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/1-introduction</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.introduction">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">2 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Azure Speech provides APIs that you can use to build speech-enabled applications. This includes:</p>
<ul>
<li><strong>Speech to text</strong>: An API that enables <em>speech recognition</em> in which your application can accept spoken input.</li>
<li><strong>Text to speech</strong>: An API that enables <em>speech synthesis</em> in which your application can provide spoken output.</li>
<li><strong>Speech Translation</strong>: An API that you can use to translate spoken input into multiple languages.</li>
<li><strong>Keyword Recognition</strong>: An API that enables your application to recognize keywords or short phrases.</li>
<li><strong>Intent Recognition</strong>: An API that uses conversational language understanding to determine the semantic meaning of spoken input.</li>
</ul>
<p>This module focuses on speech recognition and speech synthesis, which are core capabilities of any speech-enabled application.</p>
<div class="NOTE">
<p>Note</p>
<p>The code examples in this module are provided in Python, but you can use any of the available Azure Speech SDK packages to develop speech-enabled applications in your preferred language. Available SDK packages include:</p>
<ul>
<li><a data-linktype="external" href="https://pypi.org/project/azure-cognitiveservices-speech?azure-portal=true">azure-cognitiveservices-speech for Python</a></li>
<li><a data-linktype="external" href="https://www.nuget.org/packages/Microsoft.CognitiveServices.Speech?azure-portal=true">Microsoft.CognitiveServices.Speech for Microsoft .NET</a></li>
<li><a data-linktype="external" href="https://www.npmjs.com/package/microsoft-cognitiveservices-speech-sdk?azure-portal=true">microsoft-cognitiveservices-speech-sdk for JavaScript</a></li>
<li><a data-linktype="external" href="https://mvnrepository.com/artifact/com.microsoft.cognitiveservices.speech/client-sdk?azure-portal=true">Microsoft Cognitive Services Speech SDK For Java</a></li>
</ul>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>2. Provision an Azure resource for speech</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/2-create-speech-service">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/2-create-speech-service</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Provision an Azure resource for speech</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.create-speech-resource">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">2 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Before you can use Azure Speech, you need to create an Azure Speech resource in your Azure subscription. You can use either a dedicated Azure Speech resource or a Microsoft Foundry resource.</p>
<p>After you create your resource, you'll need the following information to use it from a client application through one of the supported SDKs:</p>
<ul>
<li>The <em>location</em> in which the resource is deployed (for example, <em>eastus</em>)</li>
<li>One of the <em>keys</em> assigned to your resource.</li>
</ul>
<p>You can view of these values on the <strong>Keys and Endpoint</strong> page for your resource in the Azure portal.</p>
<p>While the specific syntax and parameters can vary between language-specific SDKs, most interactions with the Azure Speech service start with the creation of a <strong>SpeechConfig</strong> object that encapsulates the connection to your Azure Speech resource.</p>
<p>For example, the following Python code instantiates a SpeechConfig object based on an Azure Speech resource in the East US region:</p>
<pre><code class="lang-python">import azure.cognitiveservices.speech as speech_sdk

speech_config = speech_sdk.SpeechConfig(your_project_key, 'eastus')
</code></pre>
<div class="NOTE">
<p>Note</p>
<p>This example assumes that the Speech SDK package for python has been installed, like this:</p>
<p><code>pip install azure-cognitiveservices-speech</code></p>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>3. Use the Azure Speech to Text API</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/3-speech-to-text">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/3-speech-to-text</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Use the Azure Speech to Text API</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.speech-to-text">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>The Azure Speech service supports speech recognition through the following features:</p>
<ul>
<li><strong>Real-time transcription</strong>: Instant transcription with intermediate results for live audio inputs.</li>
<li><strong>Fast transcription</strong>: Fastest synchronous output for situations with predictable latency.</li>
<li><strong>Batch transcription</strong>: Efficient processing for large volumes of prerecorded audio.</li>
<li><strong>Custom speech</strong>: Models with enhanced accuracy for specific domains and conditions.</li>
</ul>
<h2 id="using-the-azure-speech-sdk">Using the Azure Speech SDK</h2>
<p>While the specific details vary, depending on the SDK being used (Python, C#, and so on); there's a consistent pattern for using the <strong>Speech to text</strong> API:</p>
<p><span class="mx-imgBorder">
<img alt="A diagram showing how a SpeechRecognizer object is created from a SpeechConfig and AudioConfig, and its RecognizeOnceAsync method is used to call the Speech API." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/create-speech-enabled-apps/media/speech-to-text.png"/>
</span>
</p>
<ol>
<li>Use a <strong>SpeechConfig</strong> object to encapsulate the information required to connect to your Azure Speech resource. Specifically, its <strong>location</strong> and <strong>key</strong>.</li>
<li>Optionally, use an <strong>AudioConfig</strong> to define the input source for the audio to be transcribed. By default, this is the default system microphone, but you can also specify an audio file.</li>
<li>Use the <strong>SpeechConfig</strong> and <strong>AudioConfig</strong> to create a <strong>SpeechRecognizer</strong> object. This object is a proxy client for the <strong>Speech to text</strong> API.</li>
<li>Use the methods of the <strong>SpeechRecognizer</strong> object to call the underlying API functions. For example, the <strong>RecognizeOnceAsync()</strong> method uses the Azure Speech service to asynchronously transcribe a single spoken utterance.</li>
<li>Process the response from the Azure Speech service. In the case of the <strong>RecognizeOnceAsync()</strong> method, the result is a <strong>SpeechRecognitionResult</strong> object that includes the following properties:
<ul>
<li>Duration</li>
<li>OffsetInTicks</li>
<li>Properties</li>
<li>Reason</li>
<li>ResultId</li>
<li>Text</li>
</ul>
</li>
</ol>
<p>If the operation was successful, the <strong>Reason</strong> property has the enumerated value <strong>RecognizedSpeech</strong>, and the <strong>Text</strong> property contains the transcription. Other possible values for <strong>Result</strong> include <strong>NoMatch</strong> (indicating that the audio was successfully parsed but no speech was recognized) or <strong>Canceled</strong>, indicating that an error occurred (in which case, you can check the <strong>Properties</strong> collection for the <strong>CancellationReason</strong> property to determine what went wrong).</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>4. Use the text to speech API</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/4-text-to-speech">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/4-text-to-speech</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Use the text to speech API</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.text-to-speech">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">4 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Similarly to its <strong>Speech to text</strong> APIs, the Azure Speech service offers other REST APIs for speech synthesis:</p>
<ul>
<li>The <strong>Text to speech</strong> API, which is the primary way to perform speech synthesis.</li>
<li>The <strong>Batch synthesis</strong> API, which is designed to support batch operations that convert large volumes of text to audio - for example to generate an audio-book from the source text.</li>
</ul>
<p>You can learn more about the REST APIs in the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/batch-synthesis">Text to speech REST API documentation</a>. In practice, most interactive speech-enabled applications use the Azure Speech service through a (programming) language-specific SDK.</p>
<h2 id="using-the-azure-speech-sdk">Using the Azure Speech SDK</h2>
<p>As with speech recognition, in practice most interactive speech-enabled applications are built using the Azure Speech SDK.</p>
<p>The pattern for implementing speech synthesis is similar to that of speech recognition:</p>
<p><span class="mx-imgBorder">
<img alt="A diagram showing how a SpeechSynthesizer object is created from a SpeechConfig and AudioConfig, and its SpeakTextAsync method is used to call the Speech API." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/create-speech-enabled-apps/media/text-to-speech.png"/>
</span>
</p>
<ol>
<li>Use a <strong>SpeechConfig</strong> object to encapsulate the information required to connect to your Azure Speech resource. Specifically, its <strong>location</strong> and <strong>key</strong>.</li>
<li>Optionally, use an <strong>AudioConfig</strong> to define the output device for the speech to be synthesized. By default, this is the default system speaker, but you can also specify an audio file, or by explicitly setting this value to a null value, you can process the audio stream object that is returned directly.</li>
<li>Use the <strong>SpeechConfig</strong> and <strong>AudioConfig</strong> to create a <strong>SpeechSynthesizer</strong> object. This object is a proxy client for the <strong>Text to speech</strong> API.</li>
<li>Use the methods of the <strong>SpeechSynthesizer</strong> object to call the underlying API functions. For example, the <strong>SpeakTextAsync()</strong> method uses the Azure Speech service to convert text to spoken audio.</li>
<li>Process the response from the Azure Speech service. In the case of the <strong>SpeakTextAsync</strong> method, the result is a <strong>SpeechSynthesisResult</strong> object that contains the following properties:
<ul>
<li>AudioData</li>
<li>Properties</li>
<li>Reason</li>
<li>ResultId</li>
</ul>
</li>
</ol>
<p>When speech has been successfully synthesized, the <strong>Reason</strong> property is set to the <strong>SynthesizingAudioCompleted</strong> enumeration and the <strong>AudioData</strong> property contains the audio stream (which, depending on the <strong>AudioConfig</strong> may have been automatically sent to a speaker or file).</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>5. Configure audio format and voices</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/5-audio-format-voices">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/5-audio-format-voices</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Configure audio format and voices</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.audio-format-voices">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>When synthesizing speech, you can use a <strong>SpeechConfig</strong> object to customize the audio that is returned by the Azure Speech service.</p>
<h2 id="audio-format">Audio format</h2>
<p>The Azure Speech service supports multiple output formats for the audio stream that is generated by speech synthesis. Depending on your specific needs, you can choose a format based on the required:</p>
<ul>
<li>Audio file type</li>
<li>Sample-rate</li>
<li>Bit-depth</li>
</ul>
<p>For example, the following Python code sets the speech output format for a previously defined <strong>SpeechConfig</strong> object named <em>speech_config</em>:</p>
<pre><code class="lang-python">speech_config.set_speech_synthesis_output_format(SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)
</code></pre>
<p>For a full list of supported formats and their enumeration values, see the <a data-linktype="absolute-path" href="/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.speechsynthesisoutputformat">Azure Speech SDK documentation</a>.</p>
<h2 id="voices">Voices</h2>
<p>The Azure Speech service provides multiple voices that you can use to personalize your speech-enabled applications. Voices are identified by names that indicate a locale and a person's name - for example <code>en-GB-George</code>.</p>
<p>The following Python example code sets the voice to be used</p>
<pre><code class="lang-python">speech_config.speech_synthesis_voice_name = "en-GB-George"
</code></pre>
<p>For information about voices, see the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/language-support?tabs=tts">Azure Speech SDK documentation</a>.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>6. Use Speech Synthesis Markup Language</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/6-speech-synthesis-markup">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/6-speech-synthesis-markup</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Use Speech Synthesis Markup Language</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.speech-synthesis-markup">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>While the Azure Speech SDK enables you to submit plain text to be synthesized into speech, the service also supports an XML-based syntax for describing characteristics of the speech you want to generate. This <strong>Speech Synthesis Markup Language</strong> (SSML) syntax offers greater control over how the spoken output sounds, enabling you to:</p>
<ul>
<li>Specify a speaking style, such as "excited" or "cheerful" when using a neural voice.</li>
<li>Insert pauses or silence.</li>
<li>Specify <em>phonemes</em> (phonetic pronunciations), for example to pronounce the text "SQL" as "sequel".</li>
<li>Adjust the <em>prosody</em> of the voice (affecting the pitch, timbre, and speaking rate).</li>
<li>Use common "say-as" rules, for example to specify that a given string should be expressed as a date, time, telephone number, or other form.</li>
<li>Insert recorded speech or audio, for example to include a standard recorded message or simulate background noise.</li>
</ul>
<p>For example, consider the following SSML:</p>
<pre><code class="lang-xml">&lt;speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" 
                     xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-US"&gt; 
    &lt;voice name="en-US-AriaNeural"&gt; 
        &lt;mstts:express-as style="cheerful"&gt; 
          I say tomato 
        &lt;/mstts:express-as&gt; 
    &lt;/voice&gt; 
    &lt;voice name="en-US-GuyNeural"&gt; 
        I say &lt;phoneme alphabet="sapi" ph="t ao m ae t ow"&gt; tomato &lt;/phoneme&gt;. 
        &lt;break strength="weak"/&gt;Lets call the whole thing off! 
    &lt;/voice&gt; 
&lt;/speak&gt;
</code></pre>
<p>This SSML specifies a spoken dialog between two different neural voices, like this:</p>
<ul>
<li><strong>Ariana</strong> (<em>cheerfully</em>): "I say tomato:</li>
<li><strong>Guy</strong>: "I say tomato (pronounced <em>tom-ah-toe</em>) ... Let's call the whole thing off!"</li>
</ul>
<p>To submit an SSML description to the Speech service, you can use an appropriate method of a <strong>SpeechSynthesizer</strong> object, like this:</p>
<pre><code class="lang-python">speech_synthesizer.speak_ssml('&lt;speak&gt;...');
</code></pre>
<p>For more information about SSML, see the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/speech-synthesis-markup">Azure Speech SDK documentation</a>.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>7. Exercise - Create a speech-enabled app</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/7-exercise-speech-app">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/7-exercise-speech-app</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Create a speech-enabled app</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.exercise-speech-app">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">30 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this exercise, build a speech enabled app for both speech recognition and synthesis.</p>
<div class="NOTE">
<p>Note</p>
<p>To complete this lab, you need an <strong><a data-linktype="external" href="https://azure.microsoft.com/pricing/purchase-options/azure-account?cid=msft_learn">Azure subscription</a></strong>.</p>
</div>
<p>Launch the exercise and follow the instructions.</p>
<p><a data-linktype="external" href="https://go.microsoft.com/fwlink/?linkid=2322214&amp;azure-portal=true"><img alt="Button to launch exercise." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/create-speech-enabled-apps/media/launch-exercise.png"/></a></p>
<div class="TIP">
<p>Tip</p>
<p>After completing the exercise, if you've finished exploring Foundry Tools, delete the Azure resources that you created during the exercise.</p>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>8. Module assessment</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/8-knowledge-check">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/8-knowledge-check</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Module assessment</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.knowledge-check">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div aria-hidden="true" hidden="" id="module-unit-content">
</div>
<form aria-hidden="true" aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" hidden="" id="question-container" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>What information do you need from your Azure Speech service resource to consume it using the Azure Speech SDK?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>The location and one of the keys</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>The primary and secondary keys</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>The endpoint and one of the keys</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which object should you use to specify that the speech input to be transcribed to text is in an audio file?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>SpeechConfig</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>AudioConfig</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>SpeechRecognizer</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>How can you change the voice used in speech synthesis?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Specify a SpeechSynthesisOutputFormat enumeration in the SpeechConfig object.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Set the SpeechSynthesisVoiceName property of the SpeechConfig object to the desired voice name.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Specify a filename in the AudioConfig object.</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<form aria-hidden="true" aria-label="Knowledge check" class="margin-top-xs" data-bi-name="module-assessment" hidden="" id="module-assessment-questions-form" role="form">
<fieldset class="field">
<div id="module-assessment-questions-container" role="list"></div>
<div aria-hidden="true" hidden="" id="module-assessment-objectives-container" role="list"></div>
<div id="module-assessment-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-module-assessment-question-error" role="alert">You must answer all questions before checking your work.</p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>9. Summary</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/9-summary">https://learn.microsoft.com/en-us/training/modules/create-speech-enabled-apps/9-summary</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.create-speech-enabled-apps.summary">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">1 minute</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this module, you learned how to:</p>
<ul>
<li>Provision an Azure resource for the Azure Speech service</li>
<li>Use the Speech to text API to implement speech recognition</li>
<li>Use the Text to speech API to implement speech synthesis</li>
<li>Configure audio format and voices</li>
<li>Use Speech Synthesis Markup Language (SSML)</li>
</ul>
<p>To learn more about the Azure Speech, refer to the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/">Azure Speech service documentation</a>.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>
</body>
</html>