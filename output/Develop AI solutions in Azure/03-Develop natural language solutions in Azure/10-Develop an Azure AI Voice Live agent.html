<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Develop an Azure AI Voice Live agent</title>
    <style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    h1 { color: #0078d4; border-bottom: 2px solid #0078d4; padding-bottom: 10px; }
    h2 { color: #333; margin-top: 40px; border-bottom: 1px solid #ddd; padding-bottom: 8px; }
    .section { margin-bottom: 40px; }
    .section-header { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    .section-header a { color: #0078d4; text-decoration: none; }
    .section-header a:hover { text-decoration: underline; }
    img { max-width: 100%; height: auto; }
    pre { background: #f4f4f4; padding: 15px; overflow-x: auto; border-radius: 5px; }
    code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background: #f5f5f5; }
    .NOTE, .TIP { padding: 12px 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid; }
    .NOTE { background-color: #e7f3ff; border-color: #0078d4; }
    .NOTE > p:first-child { font-weight: bold; color: #0078d4; margin-top: 0; }
    .TIP { background-color: #e8f5e9; border-color: #4caf50; }
    .TIP > p:first-child { font-weight: bold; color: #2e7d32; margin-top: 0; }
</style>
</head>
<body>
    <h1>Develop an Azure AI Voice Live agent</h1>

    <div class="section">
        <div class="section-header">
            <h2>1. Introduction</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/1-introduction">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/1-introduction</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.introduction">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Voice-enabled applications are transforming how we interact with technology, and this module guides you through building a real-time, interactive voice solutions using advanced APIs and tools. The Azure AI Voice live API is a solution enabling low-latency, high-quality speech to speech interactions for voice agents. The API is designed for developers seeking scalable and efficient voice-driven experiences as it eliminates the need to manually orchestrate multiple components.</p>
<p>After completing this module, you'll be able to:</p>
<ul>
<li>Implement the Azure AI Voice Live API to enable real-time, bidirectional communication.</li>
<li>Set up and configure the agent session.</li>
<li>Develop and manage event handlers to create dynamic and interactive user experiences.</li>
<li>Build and deploy a Python-based web app with real-time voice interaction capabilities to Azure.</li>
</ul>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>2. Explore the Azure Voice Live API</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/2-voice-live-api">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/2-voice-live-api</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Explore the Azure Voice Live API</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.voice-live-api">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>The Voice live API enables developers to create voice-enabled applications with real-time, bidirectional communication. This unit explores its architecture, configuration, and implementation.</p>
<h2 id="key-features-of-the-voice-live-api">Key features of the Voice Live API</h2>
<p>The Voice live API provides real-time communication using WebSocket connections. It supports advanced features such as speech recognition, text-to-speech synthesis, avatar streaming, and audio processing.</p>
<ul>
<li>JSON-formatted events manage conversations, audio streams, and responses.</li>
<li>Events are categorized into client events (sent from client to server) and server events (sent from server to client).</li>
</ul>
<p>Key features include:</p>
<ul>
<li>Real-time audio processing with support for multiple formats like PCM16 and G.711.</li>
<li>Advanced voice options, including OpenAI voices and Azure custom voices.</li>
<li>Avatar integration using WebRTC for video and animation.</li>
<li>Built-in noise reduction and echo cancellation.</li>
</ul>
<div class="NOTE">
<p>Note</p>
<p>Voice Live API is optimized for Microsoft Foundry resources. We recommend using Microsoft Foundry resources for full feature availability and best Microsoft Foundry integration experience.</p>
</div>
<p>For a table of supported models and regions, visit the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/voice-live#supported-models-and-regions">Voice Live API overview</a>.</p>
<h2 id="connect-to-the-voice-live-api">Connect to the Voice Live API</h2>
<p>The Voice live API supports two authentication methods: Microsoft Entra (keyless) and API key. Microsoft Entra uses token-based authentication for a Microsoft Foundry resource. You apply a retrieved authentication token using a <code>Bearer</code> token with the <code>Authorization</code> header.</p>
<p>For the recommended keyless authentication with Microsoft Entra ID, you need to assign the <strong>Cognitive Services User</strong> role to your user account or a managed identity. You generate a token using the Azure CLI or Azure SDKs. The token must be generated with the <code>https://ai.azure.com/.default</code> scope, or the legacy <code>https://cognitiveservices.azure.com/.default</code> scope. Use the token in the <code>Authorization</code> header of the WebSocket connection request, with the format <code>Bearer &lt;token&gt;</code>.</p>
<p>For key access, an API key can be provided in one of two ways. You can use an <code>api-key</code> connection header on the prehandshake connection. This option isn't available in a browser environment. Or, you can use an <code>api-key</code> query string parameter on the request URI. Query string parameters are encrypted when using https/wss.</p>
<div class="NOTE">
<p>Note</p>
<p>The <code>api-key</code> connection header on the prehandshake connection isn't available in a browser environment.</p>
</div>
<h3 id="websocket-endpoint">WebSocket endpoint</h3>
<p>The endpoint to use varies depending on how you want to access your resources. You can access resources through a connection to the AI Foundry project (Agent), or through a connection to the model.</p>
<ul>
<li><strong>Project connection:</strong> The endpoint is <code>wss://&lt;your-ai-foundry-resource-name&gt;.services.ai.azure.com/voice-live/realtime?api-version=2025-10-01</code></li>
<li><strong>Model connection:</strong> The endpoint is <code>wss://&lt;your-ai-foundry-resource-name&gt;.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-10-01</code>.</li>
</ul>
<p>The endpoint is the same for all models. The only difference is the required <code>model</code> query parameter, or, when using the Agent service, the <code>agent_id</code> and <code>project_id</code> parameters.</p>
<h2 id="voice-live-api-events">Voice Live API events</h2>
<p>Client and server events facilitate communication and control within the Voice live API. Key client events include:</p>
<ul>
<li><code>session.update</code>: Modify session configurations.</li>
<li><code>input_audio_buffer.append</code>: Add audio data to the buffer.</li>
<li><code>response.create</code>: Generate responses via model inference.</li>
</ul>
<p>Server events provide feedback and status updates:</p>
<ul>
<li><code>session.updated</code>: Confirm session configuration changes.</li>
<li><code>response.done</code>: Indicate response generation completion.</li>
<li><code>conversation.item.created</code>: Notify when a new conversation item is added.</li>
</ul>
<p>For a full list of client/server events, visit <a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/voice-live-api-reference">Voice live API Reference</a>.</p>
<div class="NOTE">
<p>Note</p>
<p>Proper handling of events ensures seamless interaction between client and server.</p>
</div>
<h3 id="configure-session-settings-for-the-voice-live-api">Configure session settings for the Voice live API</h3>
<p>Often, the first event sent by the caller on a newly established Voice live API session is the <code>session.update</code> event. This event controls a wide set of input and output behavior. Session settings can be updated dynamically using the <code>session.update</code> event. Developers can configure voice types, modalities, turn detection, and audio formats.</p>
<p>Example configuration:</p>
<pre><code class="lang-json">{
  "type": "session.update",
  "session": {
    "modalities": ["text", "audio"],
    "voice": {
      "type": "openai",
      "name": "alloy"
    },
    "instructions": "You are a helpful assistant. Be concise and friendly.",
    "input_audio_format": "pcm16",
    "output_audio_format": "pcm16",
    "input_audio_sampling_rate": 24000,
    "turn_detection": {
      "type": "azure_semantic_vad",
      "threshold": 0.5,
      "prefix_padding_ms": 300,
      "silence_duration_ms": 500
    },
    "temperature": 0.8,
    "max_response_output_tokens": "inf"
  }
}
</code></pre>
<div class="TIP">
<p>Tip</p>
<p>Use Azure semantic VAD for intelligent turn detection and improved conversational flow.</p>
</div>
<h3 id="implement-real-time-audio-processing-with-the-voice-live-api">Implement real-time audio processing with the Voice live API</h3>
<p>Real-time audio processing is a core feature of the Voice live API. Developers can append, commit, and clear audio buffers using specific client events.</p>
<ul>
<li><strong>Append audio:</strong> Add audio bytes to the input buffer.</li>
<li><strong>Commit audio:</strong> Process the audio buffer for transcription or response generation.</li>
<li><strong>Clear audio:</strong> Remove audio data from the buffer.</li>
</ul>
<p>Noise reduction and echo cancellation can be configured to enhance audio quality. For example:</p>
<pre><code class="lang-json">{
  "type": "session.update",
  "session": {
    "input_audio_noise_reduction": {
      "type": "azure_deep_noise_suppression"
    },
    "input_audio_echo_cancellation": {
      "type": "server_echo_cancellation"
    }
  }
}
</code></pre>
<div class="NOTE">
<p>Note</p>
<p>Noise reduction improves VAD accuracy and model performance by filtering input audio.</p>
</div>
<h3 id="integrate-avatar-streaming-using-the-voice-live-api">Integrate avatar streaming using the Voice live API</h3>
<p>The Voice live API supports WebRTC-based avatar streaming for interactive applications. Developers can configure video, animation, and blendshape settings.</p>
<ul>
<li>Use the <code>session.avatar.connect</code> event to provide the client's SDP offer.</li>
<li>Configure video resolution, bitrate, and codec settings.</li>
<li>Define animation outputs such as blendshapes and visemes.</li>
</ul>
<p>Example configuration:</p>
<pre><code class="lang-json">{
  "type": "session.avatar.connect",
  "client_sdp": "&lt;client_sdp&gt;"
}
</code></pre>
<div class="TIP">
<p>Tip</p>
<p>Use high-resolution video settings for enhanced visual quality in avatar interactions.</p>
</div>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>3. Explore the AI Voice Live client library for Python</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/3-voice-live-sdk">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/3-voice-live-sdk</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Explore the AI Voice Live client library for Python</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.voice-live-sdk">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>The Azure AI Voice Live client library for Python provides a real-time, speech-to-speech client for Azure AI Voice Live API. It opens a WebSocket session to stream microphone audio to the service and receives server events for responsive conversations.</p>
<div class="IMPORTANT">
<p>Important</p>
<p>As of version 1.0.0, this SDK is async-only. The synchronous API is deprecated to focus exclusively on async patterns. All examples and samples use async/await syntax.</p>
</div>
<p>In this unit, you learn how to use the SDK to implement authentication and handle events. You also see a minimal example of creating a session. For a full reference to the Voice Live package, visit the <a data-linktype="absolute-path" href="/en-us/python/api/azure-ai-voicelive/azure.ai.voicelive?view=azure-python">voice live Package reference</a>.</p>
<h2 id="implement-authentication">Implement authentication</h2>
<p>You can implement authentication with an API key or a Microsoft Entra ID token. The following code sample shows an API key implementation. It assumes environment variables are set in a <code>.env</code> file, or directly in your environment.</p>
<pre><code class="lang-python">import asyncio
from azure.core.credentials import AzureKeyCredential
from azure.ai.voicelive import connect

async def main():
    async with connect(
        endpoint="your-endpoint",
        credential=AzureKeyCredential("your-api-key"),
        model="gpt-4o"
    ) as connection:
        # Your async code here
        pass

asyncio.run(main())
</code></pre>
<p>For production applications, Microsoft Entra authentication is recommended. The following code sample shows implementing the <code>DefaultAzureCredential</code> for authentication:</p>
<pre><code class="lang-python">import asyncio
from azure.identity.aio import DefaultAzureCredential
from azure.ai.voicelive import connect

async def main():
    credential = DefaultAzureCredential()
    
    async with connect(
        endpoint="your-endpoint",
        credential=credential,
        model="gpt-4o"
    ) as connection:
        # Your async code here
        pass

asyncio.run(main())
</code></pre>
<h2 id="handling-events">Handling events</h2>
<p>Proper handling of events ensures a more seamless interaction between the client and agent. For example, when handling a user interrupting the voice agent you need to cancel agent audio playback immediately in the client. If you don't, the client continues to play the last agent response until the interrupt is processed in the API - resulting in the agent "talking over" the user.</p>
<p>The following code sample shows some basic event handling:</p>
<pre><code class="lang-python">async for event in connection:
    if event.type == ServerEventType.SESSION_UPDATED:
        print(f"Session ready: {event.session.id}")
        # Start audio capture
        
    elif event.type == ServerEventType.INPUT_AUDIO_BUFFER_SPEECH_STARTED:
        print("User started speaking")
        # Stop playback and cancel any current response
        
    elif event.type == ServerEventType.RESPONSE_AUDIO_DELTA:
        # Play the audio chunk
        audio_bytes = event.delta
        
    elif event.type == ServerEventType.ERROR:
        print(f"Error: {event.error.message}")
</code></pre>
<h2 id="minimal-example">Minimal example</h2>
<p>The following code sample shows authenticating to the API and configuring the session.</p>
<pre><code class="lang-python">import asyncio
from azure.core.credentials import AzureKeyCredential
from azure.ai.voicelive.aio import connect
from azure.ai.voicelive.models import (
    RequestSession, Modality, InputAudioFormat, OutputAudioFormat, ServerVad, ServerEventType
)

API_KEY = "your-api-key"
ENDPOINT = "your-endpoint"
MODEL = "gpt-4o"

async def main():
    async with connect(
        endpoint=ENDPOINT,
        credential=AzureKeyCredential(API_KEY),
        model=MODEL,
    ) as conn:
        session = RequestSession(
            modalities=[Modality.TEXT, Modality.AUDIO],
            instructions="You are a helpful assistant.",
            input_audio_format=InputAudioFormat.PCM16,
            output_audio_format=OutputAudioFormat.PCM16,
            turn_detection=ServerVad(
                threshold=0.5, 
                prefix_padding_ms=300, 
                silence_duration_ms=500
            ),
        )
        await conn.session.update(session=session)

        # Process events
        async for evt in conn:
            print(f"Event: {evt.type}")
            if evt.type == ServerEventType.RESPONSE_DONE:
                break

asyncio.run(main())
</code></pre>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>4. Exercise - Develop an Azure AI Voice Live agent</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/4-exercise-develop-agent">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/4-exercise-develop-agent</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Develop an Azure AI Voice Live agent</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.exercise-develop-agent">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">30 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this exercise, you complete a Flask-based Python web app based that enables real-time voice interactions with an agent. You add the code to initialize the session, and handle session events. You use a deployment script that: deploys the AI model; creates an image of the app in Azure Container Registry (ACR) using ACR tasks; and then creates an Azure App Service instance that pulls the image. To test the app, you need an audio device with microphone and speaker capabilities.</p>
<p>While this exercise is based on Python, you can develop similar applications other language-specific SDKs; including:</p>
<ul>
<li><a data-linktype="external" href="https://www.nuget.org/packages/Azure.AI.VoiceLive/">Azure VoiceLive client library for .NET</a></li>
</ul>
<p>Tasks performed in this exercise:</p>
<ul>
<li>Download the base files for the app</li>
<li>Add code to complete the web app</li>
<li>Review the overall code base</li>
<li>Update and run the deployment script</li>
<li>View and test the application</li>
</ul>
<p>This exercise takes approximately <strong>30</strong> minutes to complete.</p>
<h2 id="before-you-start">Before you start</h2>
<p>To complete the exercise, you need:</p>
<ul>
<li>An Azure subscription. If you don't already have one, you can sign up for one <a data-linktype="external" href="https://azure.microsoft.com/">https://azure.microsoft.com/</a>.</li>
<li>An audio device with microphone and speaker capabilities.</li>
</ul>
<h2 id="get-started">Get started</h2>
<p>Select the <strong>Launch Exercise</strong> button to open the exercise instructions in a new browser window. When you're finished with the exercise, return here to:</p>
<div class="checklist">
<ul>
<li>Complete the module</li>
<li>Earn a badge for completing this module</li>
</ul>
</div>
<br/>
<a data-linktype="external" href="https://go.microsoft.com/fwlink/?linkid=2338402" target="_blank">
<img alt="Button to launch exercise." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/develop-voice-live-agent/media/launch-exercise.png"/>
</a>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>5. Module assessment</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/5-knowledge-check">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/5-knowledge-check</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Module assessment</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.knowledge-check">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div aria-hidden="true" hidden="" id="module-unit-content">
</div>
<form aria-hidden="true" aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" hidden="" id="question-container" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>What are the two authentication methods supported by the Voice Live API?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>OAuth 2.0 and JWT (JSON Web Tokens)</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Basic authentication and API keys</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Microsoft Entra (keyless) and API key</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which scope is required when generating a token for Microsoft Entra authentication?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p><code>https://cognitiveservices.azure.com/.default</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p><code>https://management.azure.com/.default</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p><code>https://graph.microsoft.com/.default</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Which protocol is used for avatar streaming integration in Voice Live API?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>HTTP/2</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>WebRTC</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>gRPC</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-4" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-4">
<span class="font-weight-semibold">4.</span>
<p>Which event should be handled to stop audio playback when a user interrupts the voice agent?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-0">
<input class="radio-dot choice-input" id="quiz-choice-3-0" name="3" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p><code>ServerEventType.RESPONSE_AUDIO_DELTA</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-1">
<input class="radio-dot choice-input" id="quiz-choice-3-1" name="3" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p><code>ServerEventType.INPUT_AUDIO_BUFFER_SPEECH_STARTED</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-2">
<input class="radio-dot choice-input" id="quiz-choice-3-2" name="3" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p><code>ServerEventType.SESSION_UPDATED</code></p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-5" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-5">
<span class="font-weight-semibold">5.</span>
<p>What is the recommended authentication method for production applications using the SDK?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-0">
<input class="radio-dot choice-input" id="quiz-choice-4-0" name="4" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>API key authentication</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-1">
<input class="radio-dot choice-input" id="quiz-choice-4-1" name="4" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Microsoft Entra authentication with DefaultAzureCredential</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-2">
<input class="radio-dot choice-input" id="quiz-choice-4-2" name="4" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Basic username/password authentication</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<form aria-hidden="true" aria-label="Knowledge check" class="margin-top-xs" data-bi-name="module-assessment" hidden="" id="module-assessment-questions-form" role="form">
<fieldset class="field">
<div id="module-assessment-questions-container" role="list"></div>
<div aria-hidden="true" hidden="" id="module-assessment-objectives-container" role="list"></div>
<div id="module-assessment-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-module-assessment-question-error" role="alert">You must answer all questions before checking your work.</p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>6. Summary</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/6-summary">https://learn.microsoft.com/en-us/training/modules/develop-voice-live-agent/6-summary</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.develop-voice-live-agent.summary">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this module, you learned about the Voice live API's features, including WebSocket connections, speech recognition, text-to-speech synthesis, and avatar streaming. You also explored Azure AI Voice Live for creating real-time speech-to-speech applications using Python, including setting up the client library and managing sessions. Additionally, you learned how to implement event handlers in Python for dynamic responses and real-time audio processing. Finally, you developed a Python-based web application using Flask, integrated it with Azure resources, and tested the application.</p>
<h2 id="additional-reading">Additional reading</h2>
<ul>
<li><a data-linktype="absolute-path" href="/en-us/azure/cognitive-services/speech-service/">What is the Speech service?</a></li>
<li><a data-linktype="absolute-path" href="/en-us/azure/ai-services/speech-service/voice-live-how-to-customize">How to customize voice live input and output</a></li>
</ul>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>
</body>
</html>