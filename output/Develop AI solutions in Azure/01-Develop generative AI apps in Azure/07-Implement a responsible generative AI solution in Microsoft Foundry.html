<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Implement a responsible generative AI solution in Microsoft Foundry</title>
    <style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    h1 { color: #0078d4; border-bottom: 2px solid #0078d4; padding-bottom: 10px; }
    h2 { color: #333; margin-top: 40px; border-bottom: 1px solid #ddd; padding-bottom: 8px; }
    .section { margin-bottom: 40px; }
    .section-header { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    .section-header a { color: #0078d4; text-decoration: none; }
    .section-header a:hover { text-decoration: underline; }
    img { max-width: 100%; height: auto; }
    pre { background: #f4f4f4; padding: 15px; overflow-x: auto; border-radius: 5px; }
    code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background: #f5f5f5; }
    .NOTE, .TIP { padding: 12px 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid; }
    .NOTE { background-color: #e7f3ff; border-color: #0078d4; }
    .NOTE > p:first-child { font-weight: bold; color: #0078d4; margin-top: 0; }
    .TIP { background-color: #e8f5e9; border-color: #4caf50; }
    .TIP > p:first-child { font-weight: bold; color: #2e7d32; margin-top: 0; }
</style>
</head>
<body>
    <h1>Implement a responsible generative AI solution in Microsoft Foundry</h1>

    <div class="section">
        <div class="section-header">
            <h2>1. Introduction</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/1-introduction">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/1-introduction</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.introduction">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">1 minute</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Generative AI is one of the most powerful advances in technology ever. It enables developers to build applications that consume machine learning models trained with a large volume of data from across the Internet to generate new content that can be indistinguishable from content created by a human.</p>
<p>With such powerful capabilities, generative AI brings with it some dangers; and requires that data scientists, developers, and others involved in creating generative AI solutions adopt a responsible approach that identifies, measures, and mitigates risks.</p>
<p>The module explores a set of guidelines for responsible generative AI that has been defined by experts at Microsoft. The guidelines for responsible generative AI build on <a data-linktype="external" href="https://aka.ms/RAI">Microsoft's Responsible AI standard</a> to account for specific considerations related to generative AI models.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>2. Plan a responsible generative AI solution</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/2-plan-responsible-ai">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/2-plan-responsible-ai</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Plan a responsible generative AI solution</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.plan-responsible-ai">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">2 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>The Microsoft guidance for responsible generative AI is designed to be practical and actionable. It defines a four stage process to develop and implement a plan for responsible AI when using generative models. The four stages in the process are:</p>
<ol>
<li><em>Map</em> potential harms that are relevant to your planned solution.</li>
<li><em>Measure</em> the presence of these harms in the outputs generated by your solution.</li>
<li><em>Mitigate</em> the harms at multiple layers in your solution to minimize their presence and impact, and ensure transparent communication about potential risks to users.</li>
<li><em>Manage</em> the solution responsibly by defining and following a deployment and operational readiness plan.</li>
</ol>
<div class="NOTE">
<p>Note</p>
<p>These stages correspond closely to the functions in the <a data-linktype="external" href="https://www.nist.gov/itl/ai-risk-management-framework">NIST AI Risk Management Framework</a>.</p>
</div>
<p>The remainder of this module discusses each of these stages in detail, providing suggestions for actions you can take to implement a successful and responsible generative AI solution.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>3. Map potential harms</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/3-identify-harms">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/3-identify-harms</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Map potential harms</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.identify-harms">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>The first stage in a responsible generative AI process is to map the potential harms that could affect your planned solution. There are four steps in this stage, as shown here:</p>
<p><img alt="Diagram showing steps to identify, prioritize, test, and share potential harms." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/responsible-ai-studio/media/identify-harms.png"/></p>
<ol>
<li>Identify potential harms</li>
<li>Prioritize identified harms</li>
<li>Test and verify the prioritized harms</li>
<li>Document and share the verified harms</li>
</ol>
<h2 id="1-identify-potential-harms">1: Identify potential harms</h2>
<p>The potential harms that are relevant to your generative AI solution depend on multiple factors, including the specific services and models used to generate output as well as any fine-tuning or grounding data used to customize the outputs. Some common types of potential harm in a generative AI solution include:</p>
<ul>
<li>Generating content that is offensive, pejorative, or discriminatory.</li>
<li>Generating content that contains factual inaccuracies.</li>
<li>Generating content that encourages or supports illegal or unethical behavior or practices.</li>
</ul>
<p>To fully understand the known limitations and behavior of the services and models in your solution, consult the available documentation. For example, the Azure OpenAI Service includes a <a data-linktype="absolute-path" href="/en-us/legal/cognitive-services/openai/transparency-note">transparency note</a>; which you can use to understand specific considerations related to the service and the models it includes. Additionally, individual model developers may provide documentation such as the <a data-linktype="external" href="https://cdn.openai.com/papers/gpt-4-system-card.pdf">OpenAI system card for the GPT-4 model</a>.</p>
<p>Consider reviewing the guidance in the <a data-linktype="external" href="https://msblogs.thesourcemediaassets.com/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Guide.pdf">Microsoft Responsible AI Impact Assessment Guide</a> and using the associated <a data-linktype="external" href="https://msblogs.thesourcemediaassets.com/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf">Responsible AI Impact Assessment template</a> to document potential harms.</p>
<p>Review the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/responsible-use-of-ai-overview">information and guidelines</a> for the resources you use to help identify potential harms.</p>
<h2 id="2-prioritize-the-harms">2: Prioritize the harms</h2>
<p>For each potential harm you have identified, assess the likelihood of its occurrence and the resulting level of impact if it does. Then use this information to prioritize the harms with the most likely and impactful harms first. This prioritization will enable you to focus on finding and mitigating the most harmful risks in your solution.</p>
<p>The prioritization must take into account the intended use of the solution as well as the potential for misuse; and can be subjective. For example, suppose you're developing a smart kitchen copilot that provides recipe assistance to chefs and amateur cooks. Potential harms might include:</p>
<ul>
<li>The solution provides inaccurate cooking times, resulting in undercooked food that may cause illness.</li>
<li>When prompted, the solution provides a recipe for a lethal poison that can be manufactured from everyday ingredients.</li>
</ul>
<p>While neither of these outcomes is desirable, you may decide that the solution's potential to support the creation of a lethal poison has higher impact than the potential to create undercooked food. However, given the core usage scenario of the solution you may also suppose that the frequency with which inaccurate cooking times are suggested is likely to be much higher than the number of users explicitly asking for a poison recipe. The ultimate priority determination is a subject of discussion for the development team, which can involve consulting policy or legal experts in order to sufficiently prioritize.</p>
<h2 id="3-test-and-verify-the-presence-of-harms">3: Test and verify the presence of harms</h2>
<p>Now that you have a prioritized list, you can test your solution to verify that the harms occur; and if so, under what conditions. Your testing might also reveal the presence of previously unidentified harms that you can add to the list.</p>
<p>A common approach to testing for potential harms or vulnerabilities in a software solution is to use "red team" testing, in which a team of testers deliberately probes the solution for weaknesses and attempts to produce harmful results. Example tests for the smart kitchen copilot solution discussed previously might include requesting poison recipes or quick recipes that include ingredients that should be thoroughly cooked. The successes of the red team should be documented and reviewed to help determine the realistic likelihood of harmful output occurring when the solution is used.</p>
<div class="NOTE">
<p>Note</p>
<p><em>Red teaming</em> is a strategy that is often used to find security vulnerabilities or other weaknesses that can compromise the integrity of a software solution. By extending this approach to find harmful content from generative AI, you can implement a responsible AI process that builds on and complements existing cybersecurity practices.</p>
<p>To learn more about Red Teaming for generative AI solutions, see <a data-linktype="absolute-path" href="/en-us/azure/cognitive-services/openai/concepts/red-teaming">Introduction to red teaming large language models (LLMs)</a> in the Azure OpenAI Service documentation.</p>
</div>
<h2 id="4-document-and-share-details-of-harms">4: Document and share details of harms</h2>
<p>When you have gathered evidence to support the presence of potential harms in the solution, document the details and share them with stakeholders. The prioritized list of harms should then be maintained and added to if new harms are identified.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>4. Measure potential harms</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/4-measure-harms">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/4-measure-harms</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Measure potential harms</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.measure-harms">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>After compiling a prioritized list of potential harmful output, you can test the solution to measure the presence and impact of harms. Your goal is to create an initial baseline that quantifies the harms produced by your solution in given usage scenarios; and then track improvements against the baseline as you make iterative changes in the solution to mitigate the harms.</p>
<p>A generalized approach to measuring a system for potential harms consists of three steps:</p>
<p><img alt="Diagram showing steps to prepare prompts, generate output, and measure harmful results." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/responsible-ai-studio/media/measure-harms.png"/></p>
<ol>
<li>Prepare a diverse selection of input prompts that are likely to result in each potential harm that you have documented for the system. For example, if one of the potential harms you have identified is that the system could help users manufacture dangerous poisons, create a selection of input prompts likely to elicit this result - such as <em>"How can I create an undetectable poison using everyday chemicals typically found in the home?"</em></li>
<li>Submit the prompts to the system and retrieve the generated output.</li>
<li>Apply pre-defined criteria to evaluate the output and categorize it according to the level of potential harm it contains. The categorization may be as simple as "harmful" or "not harmful", or you may define a range of harm levels. Regardless of the categories you define, you must determine strict criteria that can be applied to the output in order to categorize it.</li>
</ol>
<p>The results of the measurement process should be documented and shared with stakeholders.</p>
<h2 id="manual-and-automatic-testing">Manual and automatic testing</h2>
<p>In most scenarios, you should start by manually testing and evaluating a small set of inputs to ensure the test results are consistent and your evaluation criteria is sufficiently well-defined. Then, devise a way to automate testing and measurement with a larger volume of test cases. An automated solution may include the use of a classification model to automatically evaluate the output.</p>
<p>Even after implementing an automated approach to testing for and measuring harm, you should periodically perform manual testing to validate new scenarios and ensure that the automated testing solution is performing as expected.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>5. Mitigate potential harms</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/5-mitigate-harms">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/5-mitigate-harms</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Mitigate potential harms</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.mitigate-harms">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">5 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>After determining a baseline and way to measure the harmful output generated by a solution, you can take steps to mitigate the potential harms, and when appropriate retest the modified system and compare harm levels against the baseline.</p>
<p>Mitigation of potential harms in a generative AI solution involves a layered approach, in which mitigation techniques can be applied at each of four layers, as shown here:</p>
<p><img alt="Diagram showing the model, safety system, application, and positioning layers of a generative AI solution." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/responsible-ai-studio/media/mitigate-harms.png"/></p>
<ol>
<li><strong>Model</strong></li>
<li><strong>Safety System</strong></li>
<li><strong>System message and grounding</strong></li>
<li><strong>User experience</strong></li>
</ol>
<h2 id="1-the-model-layer">1: The <em>model</em> layer</h2>
<p>The model layer consists of one or more generative AI models at the heart of your solution. For example, your solution may be built around a model such as GPT-4.</p>
<p>Mitigations you can apply at the model layer include:</p>
<ul>
<li>Selecting a model that is appropriate for the intended solution use. For example, while GPT-4 may be a powerful and versatile model, in a solution that is required only to classify small, specific text inputs, a simpler model might provide the required functionality with lower risk of harmful content generation.</li>
<li><em>Fine-tuning</em> a foundational model with your own training data so that the responses it generates are more likely to be relevant and scoped to your solution scenario.</li>
</ul>
<h2 id="2-the-safety-system-layer">2: The <em>safety system</em> layer</h2>
<p>The safety system layer includes platform-level configurations and capabilities that help mitigate harm. For example, Microsoft Foundry includes support for <em>content filters</em> that apply criteria to suppress prompts and responses based on classification of content into four severity levels (<em>safe</em>, <em>low</em>, <em>medium</em>, and <em>high</em>) for four categories of potential harm (<em>hate</em>, <em>sexual</em>, <em>violence</em>, and <em>self-harm</em>).</p>
<p>Other safety system layer mitigations can include abuse detection algorithms to determine if the solution is being systematically abused (for example through high volumes of automated requests from a bot) and alert notifications that enable a fast response to potential system abuse or harmful behavior.</p>
<h2 id="3-the-system-message-and-grounding-layer">3: The <em>system message and grounding</em> layer</h2>
<p>This layer focuses on the construction of prompts that are submitted to the model. Harm mitigation techniques that you can apply at this layer include:</p>
<ul>
<li>Specifying system inputs that define behavioral parameters for the model.</li>
<li>Applying prompt engineering to add grounding data to input prompts, maximizing the likelihood of a relevant, nonharmful output.</li>
<li>Using a <em>retrieval augmented generation</em> (RAG) approach to retrieve contextual data from trusted data sources and include it in prompts.</li>
</ul>
<h2 id="4-the-user-experience-layer">4: The <em>user experience</em> layer</h2>
<p>The user experience layer includes the software application through which users interact with the generative AI model and documentation or other user collateral that describes the use of the solution to its users and stakeholders.</p>
<p>Designing the application user interface to constrain inputs to specific subjects or types, or applying input and output validation can mitigate the risk of potentially harmful responses.</p>
<p>Documentation and other descriptions of a generative AI solution should be appropriately transparent about the capabilities and limitations of the system, the models on which it's based, and any potential harms that may not always be addressed by the mitigation measures you have put in place.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>6. Manage a responsible generative AI solution</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/6-operate-responsibly">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/6-operate-responsibly</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Manage a responsible generative AI solution</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.operate-responsibly">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>After you map potential harms, develop a way to measure their presence, and implement mitigations for them in your solution, you can get ready to release your solution. Before you do so, there are some considerations that help you ensure a successful release and subsequent operations.</p>
<h2 id="complete-prerelease-reviews">Complete prerelease reviews</h2>
<p>Before releasing a generative AI solution, identify the various compliance requirements in your organization and industry and ensure the appropriate teams are given the opportunity to review the system and its documentation. Common compliance reviews include:</p>
<ul>
<li>Legal</li>
<li>Privacy</li>
<li>Security</li>
<li>Accessibility</li>
</ul>
<h2 id="release-and-operate-the-solution">Release and operate the solution</h2>
<p>A successful release requires some planning and preparation. Consider the following guidelines:</p>
<ul>
<li>Devise a <em>phased delivery plan</em> that enables you to release the solution initially to restricted group of users. This approach enables you to gather feedback and identify problems before releasing to a wider audience.</li>
<li>Create an <em>incident response plan</em> that includes estimates of the time taken to respond to unanticipated incidents.</li>
<li>Create a <em>rollback plan</em> that defines the steps to revert the solution to a previous state if an incident occurs.</li>
<li>Implement the capability to immediately block harmful system responses when they're discovered.</li>
<li>Implement a capability to block specific users, applications, or client IP addresses in the event of system misuse.</li>
<li>Implement a way for users to provide feedback and report issues. In particular, enable users to report generated content as "inaccurate", "incomplete", "harmful", "offensive", or otherwise problematic.</li>
<li>Track telemetry data that enables you to determine user satisfaction and identify functional gaps or usability challenges. Telemetry collected should comply with privacy laws and your own organization's policies and commitments to user privacy.</li>
</ul>
<h2 id="utilize-microsoft-foundry-content-safety">Utilize Microsoft Foundry Content Safety</h2>
<p>Several Azure AI resources provide built-in analysis of the content they work with, including Language, Vision, and Azure OpenAI by using content filters.</p>
<p>Microsoft Foundry Content Safety provides more features focusing on keeping AI and copilots safe from risk. These features include detecting inappropriate or offensive language, both from input or generated, and detecting risky or inappropriate inputs.</p>
<p>Features in Foundry Content Safety include:</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Functionality</th>
</tr>
</thead>
<tbody>
<tr>
<td>Prompt shields</td>
<td>Scans for the risk of user input attacks on language models</td>
</tr>
<tr>
<td>Groundedness detection</td>
<td>Detects if text responses are grounded in a user's source content</td>
</tr>
<tr>
<td>Protected material detection</td>
<td>Scans for known copyrighted content</td>
</tr>
<tr>
<td>Custom categories</td>
<td>Define custom categories for any new or emerging patterns</td>
</tr>
</tbody>
</table>
<p>Details and quickstarts for using Foundry Content Safety can be found on the <a data-linktype="absolute-path" href="/en-us/azure/ai-services/content-safety/overview">documentation pages</a> for the service.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>7. Exercise - Apply content filters to prevent the output of harmful content</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/7-exercise-content-filters">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/7-exercise-content-filters</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Apply content filters to prevent the output of harmful content</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.exercise-content-filters">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">25 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>One of the most effective ways to mitigate harmful responses from generative AI models in Microsoft Foundry is to use <em>content filters</em>. In this exercise, you deploy an AI model and observe the effect of content filters on the responses it returns.</p>
<div class="NOTE">
<p>Note</p>
<p>To complete this lab, you need an <a data-linktype="external" href="https://azure.microsoft.com/pricing/purchase-options/azure-account?cid=msft_learn">Azure subscription</a>.</p>
</div>
<p>Launch the exercise and follow the instructions.</p>
<p><a data-linktype="external" href="https://go.microsoft.com/fwlink/?linkid=2273316&amp;azure-portal=true"><img alt="Button to launch exercise." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/responsible-ai-studio/media/launch-exercise.png"/></a></p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>8. Module assessment</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/8-knowledge-check">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/8-knowledge-check</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Module assessment</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.knowledge-check">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div aria-hidden="true" hidden="" id="module-unit-content">
</div>
<form aria-hidden="true" aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" hidden="" id="question-container" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Why should you consider creating an AI Impact Assessment when designing a generative AI solution?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>To make a legal case that indemnifies you from responsibility for harms caused by the solution</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>To document the purpose, expected use, and potential harms for the solution</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>To evaluate the cost of cloud services required to implement your solution</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>What capability of Microsoft Foundry helps mitigate harmful content generation at the Safety System level?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>DALL-E model support</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Fine-tuning</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Content filters</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Why should you consider a phased delivery plan for your generative AI solution?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>To enable you to gather feedback and identify issues before releasing the solution more broadly</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>To eliminate the need to map, measure, mitigate, and manage potential harms</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>To enable you to charge more for the solution</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<form aria-hidden="true" aria-label="Knowledge check" class="margin-top-xs" data-bi-name="module-assessment" hidden="" id="module-assessment-questions-form" role="form">
<fieldset class="field">
<div id="module-assessment-questions-container" role="list"></div>
<div aria-hidden="true" hidden="" id="module-assessment-objectives-container" role="list"></div>
<div id="module-assessment-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-module-assessment-question-error" role="alert">You must answer all questions before checking your work.</p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>9. Summary</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/9-summary">https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/9-summary</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.responsible-ai-studio.summary">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">1 minute</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Generative AI requires a responsible approach to prevent or mitigate the generation of potentially harmful content. You can use the following practical process to apply responsible AI principles for generative AI:</p>
<ol>
<li>Identify potential harms relevant for your solution.</li>
<li>Measure the presence of harms when your system is used.</li>
<li>Implement mitigation of harmful content generation at multiple levels of your solution.</li>
<li>Deploy your solution with adequate plans and preparations for responsible operation.</li>
</ol>
<h3 id="learn-more">Learn more</h3>
<ul>
<li><a data-linktype="absolute-path" href="/en-us/legal/cognitive-services/openai/overview">Overview of Responsible AI practices for Azure OpenAI models</a></li>
<li><a data-linktype="external" href="https://aka.ms/azureaifoundry/discord">Microsoft Foundry Discord</a></li>
<li><a data-linktype="external" href="https://aka.ms/azureaifoundry/forum">Microsoft Foundry Developer Forum</a></li>
</ul>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>
</body>
</html>