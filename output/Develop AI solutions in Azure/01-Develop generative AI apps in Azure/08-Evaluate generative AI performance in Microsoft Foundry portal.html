<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluate generative AI performance in Microsoft Foundry portal</title>
    <style>
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; line-height: 1.6; }
    h1 { color: #0078d4; border-bottom: 2px solid #0078d4; padding-bottom: 10px; }
    h2 { color: #333; margin-top: 40px; border-bottom: 1px solid #ddd; padding-bottom: 8px; }
    .section { margin-bottom: 40px; }
    .section-header { background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }
    .section-header a { color: #0078d4; text-decoration: none; }
    .section-header a:hover { text-decoration: underline; }
    img { max-width: 100%; height: auto; }
    pre { background: #f4f4f4; padding: 15px; overflow-x: auto; border-radius: 5px; }
    code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
    table { border-collapse: collapse; width: 100%; margin: 15px 0; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    th { background: #f5f5f5; }
    .NOTE, .TIP { padding: 12px 15px; margin: 15px 0; border-radius: 5px; border-left: 4px solid; }
    .NOTE { background-color: #e7f3ff; border-color: #0078d4; }
    .NOTE > p:first-child { font-weight: bold; color: #0078d4; margin-top: 0; }
    .TIP { background-color: #e8f5e9; border-color: #4caf50; }
    .TIP > p:first-child { font-weight: bold; color: #2e7d32; margin-top: 0; }
</style>
</head>
<body>
    <h1>Evaluate generative AI performance in Microsoft Foundry portal</h1>

    <div class="section">
        <div class="section-header">
            <h2>1. Introduction</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/1-introduction">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/1-introduction</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.introduction">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">2 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Evaluating your generative AI apps is crucial for several reasons. First and foremost, it ensures quality assurance. By assessing your app's performance, you can identify and address any issues, ensuring that it provides accurate and relevant responses. High quality responses lead to improved user satisfaction. When users receive accurate and helpful responses, they're more likely to have a positive experience and continue using your application.</p>
<p>Evaluation is also essential for continuous improvement. By analyzing the results of your evaluations, you can identify areas for enhancement and iteratively improve your app's performance. The ongoing process of evaluation and improvement helps you stay ahead of user needs and expectations, ensuring that your app remains effective and valuable.</p>
<p>In this module, you learn how to use the Microsoft Foundry portal to evaluate your generative AI apps. While you explore some of the features of Microsoft Foundry, the focus is on understanding the importance of evaluation and how it can benefit your app development process.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>2. Assess the model performance</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/2-assess-models">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/2-assess-models</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Assess the model performance</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.assess-models">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">6 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Evaluating your model's performance at different phases is crucial to ensure its effectiveness and reliability. Before exploring the various options you have to evaluate your model, let's explore the aspects of your application you can evaluate.</p>
<p>When you develop a generative AI app, you use a language model in your chat application to generate a response. To help you decide which model you want to integrate into your application, you can evaluate the performance of an individual language model:</p>
<p><span class="mx-imgBorder">
<img alt="Diagram of an interaction with a language model." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/interact-model.png"/>
</span>
</p>
<p>An input (1) is provided to a language model (2), and a response is generated as output (3). The model is then evaluated by analyzing the input, the output, and optionally comparing it to predefined expected output.</p>
<p>When you develop a generative AI app, you may integrate a language model into a chat flow:</p>
<p><span class="mx-imgBorder">
<img alt="Diagram of a chat flow using a language model." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-flow-diagram.png"/>
</span>
</p>
<p>A chat flow allows you to orchestrate executable flows that can combine multiple language models and Python code. The flow expects an input (1), processes it through executing various nodes (2), and generates an output (3). You can evaluate a complete chat flow, and its individual components.</p>
<p>When evaluating your solution, you can start with testing an individual model, and eventually test a complete chat flow to validate whether your generative AI app is working as expected.</p>
<p>Let's explore several approaches to evaluate your model and chat flow, or generative AI app.</p>
<h2 id="model-benchmarks">Model benchmarks</h2>
<p>Model benchmarks are publicly available metrics across models and datasets. These benchmarks help you understand how your model performs relative to others. Some commonly used benchmarks include:</p>
<ul>
<li><strong>Accuracy</strong>: Compares model generated text with correct answer according to the dataset. Result is one if generated text matches the answer exactly, and zero otherwise.</li>
<li><strong>Coherence</strong>: Measures whether the model output flows smoothly, reads naturally, and resembles human-like language</li>
<li><strong>Fluency</strong>: Assesses how well the generated text adheres to grammatical rules, syntactic structures, and appropriate usage of vocabulary, resulting in linguistically correct and natural-sounding responses.</li>
<li><strong>GPT similarity</strong>: Quantifies the semantic similarity between a ground truth sentence (or document) and the prediction sentence generated by an AI model.</li>
</ul>
<p>In the Microsoft Foundry portal, you can explore the model benchmarks for all available models, before deploying a model:</p>
<p><span class="mx-imgBorder">
<a data-linktype="relative-path" href="../../wwl-data-ai/evaluate-models-azure-ai-studio/media/model-benchmarks.png#lightbox">
<img alt="Screenshot of model benchmarks in Microsoft Foundry portal." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/model-benchmarks.png"/>
</a>
</span>
</p>
<h2 id="manual-evaluations">Manual evaluations</h2>
<p>Manual evaluations involve human raters who assess the quality of the model's responses. This approach provides insights into aspects that automated metrics might miss, such as context relevance and user satisfaction. Human evaluators can rate responses based on criteria like relevance, informativeness, and engagement.</p>
<h2 id="ai-assisted-metrics">AI-assisted metrics</h2>
<p>AI-assisted metrics use advanced techniques to evaluate model performance. These metrics can include:</p>
<ul>
<li><p><strong>Generation quality metrics</strong>: These metrics evaluate the overall quality of the generated text, considering factors like creativity, coherence, and adherence to the desired style or tone.</p>
</li>
<li><p><strong>Risk and safety metrics</strong>: These metrics assess the potential risks and safety concerns associated with the model's outputs. They help ensure that the model doesn't generate harmful or biased content.</p>
</li>
</ul>
<h2 id="natural-language-processing-metrics">Natural language processing metrics</h2>
<p>Natural language processing (NLP) metrics are also valuable in evaluating model performance. One such metric is the <strong>F1-score</strong>, which measures the ratio of the number of shared words between the generated and ground truth answers. The F1-score is useful for tasks like text classification and information retrieval, where precision and recall are important. Other common NLP metrics include:</p>
<ul>
<li><strong>BLEU</strong>: Bilingual Evaluation Understudy metric</li>
<li><strong>METEOR</strong>: Metric for Evaluation of Translation with Explicit Ordering</li>
<li><strong>ROUGE</strong>: Recall-Oriented Understudy for Gisting Evaluation</li>
</ul>
<p>All of these metrics are used to quantify the level of overlap in the model-generated response and the ground truth (expected response).</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>3. Manually evaluate the performance of a model</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/3-manual-evaluations">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/3-manual-evaluations</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Manually evaluate the performance of a model</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.manual-evaluations">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">7 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>During the early phases of the development of your generative AI app, you want to experiment and iterate quickly. To easily assess whether your selected language model and app, created with prompt flow, meet your requirements, you can manually evaluate models and flows in the Microsoft Foundry portal.</p>
<p>Even when your model and app are already in production, manual evaluations are a crucial part of assessing performance. As manual evaluations are done by humans, they can provide insights that automated metrics might miss.</p>
<p>Let's explore how you can manually evaluate your selected models and app in the Microsoft Foundry portal.</p>
<h2 id="prepare-your-test-prompts">Prepare your test prompts</h2>
<p>To begin the manual evaluation process, it's essential to prepare a diverse set of test prompts that reflect the range of queries and tasks your app is expected to handle. These prompts should cover various scenarios, including common user questions, edge cases, and potential failure points. By doing so, you can comprehensively assess the app's performance and identify areas for improvement.</p>
<h2 id="test-the-selected-model-in-the-chat-playground">Test the selected model in the chat playground</h2>
<p>When you develop a chat application, you use a language model to generate a response. You create a chat application by developing a prompt flow that encapsulates your chat application's logic, which can use multiple language models to ultimately generate a response to a user question.</p>
<p>Before you test your app's response, you can test the selected language model's response to verify the individual model works as expected. You can test a model you deployed in the Microsoft Foundry portal by interacting with it in the <strong>chat playground</strong>.</p>
<p><span class="mx-imgBorder">
<a data-linktype="relative-path" href="../../wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-playground.png#lightbox">
<img alt="Screenshot of the chat playground in the Microsoft Foundry portal." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-playground.png"/>
</a>
</span>
</p>
<p>The chat playground is ideal for early development. You can enter a prompt, see how the model responds, and tweak the prompt or system message to make improvements. After applying the changes, you can test a prompt again to evaluate whether the model's performance indeed improved.</p>
<h2 id="evaluate-multiple-prompts-with-manual-evaluations">Evaluate multiple prompts with manual evaluations</h2>
<p>The chat playground is an easy way to get started. When you want to manually evaluate multiple prompts more quickly, you can use the <strong>manual evaluations</strong> feature. This feature allows you to upload a dataset with multiple questions, and optionally add an expected response, to evaluate the model's performance on a larger test dataset.</p>
<p><span class="mx-imgBorder">
<a data-linktype="relative-path" href="../../wwl-data-ai/evaluate-models-azure-ai-studio/media/manual-evaluations.png#lightbox">
<img alt="Screenshot of manual evaluations in the Microsoft Foundry portal." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/manual-evaluations.png"/>
</a>
</span>
</p>
<p>You can rate the model's responses with the thumbs up or down feature. Based on the overall rating, you can try to improve your model by changing input prompt, the system message, the model, or the model's parameters.</p>
<p>When you use manual evaluations, you can more quickly evaluate the model's performance based on a diverse test dataset and improve the model based on the test results.</p>
<p>After manually evaluating an individual model, you can integrate the model into a chat application with prompt flow. Any flow you create with prompt flow can also be evaluated manually or automatically. Next, let's explore the evaluation of flows.</p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>4. Automated evaluations</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/3b-automated-evaluations">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/3b-automated-evaluations</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Automated evaluations</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.automated-evaluations">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">4 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>Automated evaluations in Microsoft Foundry portal enable you to assess the quality and content safety performance of models, datasets, or prompt flows.</p>
<h2 id="evaluation-data">Evaluation data</h2>
<p>To evaluate a model, you need a dataset of prompts and responses (and optionally, expected responses as "ground truth"). You can compile this dataset manually or use the output from an existing application; but a useful way to get started is to use an AI model to generate a set of prompts and responses related to a specific subject. You can then edit the generated prompts and responses to reflect your desired output, and use them as ground truth to evaluate the responses from another model.</p>
<p><img alt="Screenshot of AI-generated evaluation data." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/ai-generated-test-data.png"/></p>
<h2 id="evaluation-metrics">Evaluation metrics</h2>
<p>Automated evaluation enables you to choose which <em>evaluators</em> you want to assess your model's responses, and which metrics those evaluators should calculate. There are evaluators that help you measure:</p>
<ul>
<li><strong>AI Quality</strong>: The quality of your model's responses is measured by using AI models to evaluate them for metrics like <em>coherence</em> and <em>relevance</em> and by using standard NLP metrics like F1 score, BLEU, METEOR, and ROUGE based on ground truth (in the form of expected response text)</li>
<li><strong>Risk and safety</strong>: evaluators that assess the responses for content safety issues, including violence, hate, sexual content, and content related to self-harm.</li>
</ul>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>5. Exercise - Evaluate generative AI model performance</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/5-exercise">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/5-exercise</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Evaluate generative AI model performance</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.exercise">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">15 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>If you have an Azure subscription, you can use Microsoft Foundry portal to evaluate the performance of a generative AI app.</p>
<div class="NOTE">
<p>Note</p>
<p>If you don't have an Azure subscription, and you want to explore Azure AI Studio, you can <a data-linktype="external" href="https://azure.microsoft.com/pricing/purchase-options/azure-account?cid=msft_learn">sign up for an account</a>, which includes credits for the first 30 days.</p>
</div>
<p>Launch the exercise and follow the instructions.</p>
<p><a data-linktype="external" href="https://go.microsoft.com/fwlink/?linkid=2277720&amp;azure-portal=true"><img alt="Button to launch exercise." data-linktype="relative-path" src="https://learn.microsoft.com/en-us/training/wwl-data-ai/evaluate-models-azure-ai-studio/media/launch-exercise.png"/></a></p>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>6. Module assessment</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/6-knowledge-check">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/6-knowledge-check</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Module assessment</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.knowledge-check">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">3 minutes</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div aria-hidden="true" hidden="" id="module-unit-content">
</div>
<form aria-hidden="true" aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" hidden="" id="question-container" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Which evaluation technique can you use to apply your own judgement about the quality of responses to a set of specific prompts?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Model benchmarks</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Manual evaluations</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Automated evaluations</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which evaluator compares generated responses to ground truth based on standard metrics?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Coherence</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>F1 Score</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Protected material</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Which evaluator metric uses an AI model to judge the structure and logical flow of ideas in a response?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Coherence</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>F1 Score</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>protected material</p>
</div>
<div ariahidden="true" class="font-weight-semibold position-absolute right-0 margin-right-md answer-result-indicator" hidden="">
<span class="icon"></span>
<span class="answer-result-text"></span>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<form aria-hidden="true" aria-label="Knowledge check" class="margin-top-xs" data-bi-name="module-assessment" hidden="" id="module-assessment-questions-form" role="form">
<fieldset class="field">
<div id="module-assessment-questions-container" role="list"></div>
<div aria-hidden="true" hidden="" id="module-assessment-objectives-container" role="list"></div>
<div id="module-assessment-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-module-assessment-question-error" role="alert">You must answer all questions before checking your work.</p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>

    <div class="section">
        <div class="section-header">
            <h2>7. Summary</h2>
            <a href="https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/7-summary">https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/7-summary</a>
        </div>
        <div class="content"><main class="layout-body-main has-body-background-dark" data-bi-name="content" dir="ltr" id="main" lang="en-us" role="main">
<div data-main-column="">
<!-- Article header -->

<!-- Unit navigation menu -->

<!-- Main content area -->
<div class="content"><div class="modular-content-container has-body-background box">
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div class="xp-tag position-absolute top-0 right-0 margin-top-xs margin-top-sm-tablet margin-top-lg-desktop margin-top-xs-interactive margin-right-sm margin-right-lg-tablet margin-right-sm-interactive" data-progress-uid="learn.wwl.evaluate-models-azure-ai-studio.summary">
<div class="xp-tag-hexagon">
<span class="xp-tag-icon is-shown-complete docon docon-check">
<span class="visually-hidden">Completed</span>
</span>
<span class="xp-tag-xp"></span>
</div>
</div>
<ul class="metadata page-metadata" id="module-unit-metadata">
<li id="module-unit-total-time">1 minute</li>
</ul>
<div aria-hidden="true" hidden="" id="module-unit-module-assessment-message-container"></div>
<div hidden="" id="module-unit-notification-container"></div>
<div id="module-unit-content">
<p>In this module, you learned to:</p>
<ul>
<li>Understand model benchmarks.</li>
<li>Perform manual evaluations.</li>
<li>Perform automated evaluations.</li>
</ul>
<h3 id="learn-more">Learn more</h3>
<ul>
<li><a data-linktype="absolute-path" href="/en-us/azure/ai-foundry/concepts/observability">Observability in generative AI</a></li>
<li><a data-linktype="external" href="https://aka.ms/azureaifoundry/discord">Microsoft Foundry Discord</a></li>
<li><a data-linktype="external" href="https://aka.ms/azureaifoundry/forum">Microsoft Foundry Developer Forum</a></li>
</ul>
</div>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
</div>
</div>
<!-- Feedback area -->
<div class="modular-content-container margin-block-xs">
<section class="feedback-section section is-full-height is-uniform padding-block-none position-relative">
<div class="font-weight-semibold display-none" id="ms--unit-support-message"></div>
<div id="ms--unit-user-feedback">
<!-- feedback section -->

<!-- end feedback section -->
</div>
</section>
</div>
<!-- Interactive footer area -->
</div>
</main></div>
    </div>
</body>
</html>